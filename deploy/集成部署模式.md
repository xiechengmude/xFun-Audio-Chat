# Fun-Audio-Chat 三模型集成部署方案

> **版本**: v1.3-20260108
> **架构**: S2S (原生) + TTS (vLLM可选) + ASR (funasr)

---

## 目录

- [架构概览](#架构概览)
- [vLLM 兼容性分析](#vllm-兼容性分析)
- [三模型详解](#三模型详解)
- [部署模式](#部署模式)
- [接口规范](#接口规范)
- [集成部署流程](#集成部署流程)
- [运维监控](#运维监控)

---

## 架构概览

### 三种调用模式

| 模式 | 功能 | 输入 | 输出 | 接口 |
|------|------|------|------|------|
| **S2S 对话** | 语音对话 | 语音 | 语音+文本 | WebSocket |
| **TTS 合成** | 文本转语音 | 文本 | 语音 | HTTP |
| **ASR 识别** | 语音转文本 | 语音 | 文本 | HTTP |

### 服务栈组成

```
┌─────────────────────────────────────────────────────────────────────┐
│                      Fun-Audio-Chat 服务栈                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                    主服务 (server.py)                        │   │
│  │                    Port: 8002                                │   │
│  │  ┌─────────────────────┐  ┌─────────────────────────────┐   │   │
│  │  │  S2S 语音对话模型    │  │    TTS 语音合成模型          │   │   │
│  │  │  Fun-Audio-Chat-8B  │  │  Fun-CosyVoice3-0.5B-2512   │   │   │
│  │  │  GPU:0 (~18GB)      │  │  GPU:1 (~4GB)               │   │   │
│  │  └─────────────────────┘  └─────────────────────────────┘   │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │               ASR 服务 (asr_server.py)                       │   │
│  │               Port: 8003                                     │   │
│  │  ┌─────────────────────────────────────────────────────────┐ │   │
│  │  │              ASR 语音识别模型                             │ │   │
│  │  │              Fun-ASR-Nano-2512                           │ │   │
│  │  │              GPU:0 (~3GB)                                │ │   │
│  │  └─────────────────────────────────────────────────────────┘ │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 能力矩阵

| 模型 | 功能 | 输入 | 输出 | 显存 | 端口 |
|------|------|------|------|------|------|
| **Fun-Audio-Chat-8B** | 语音对话 (S2S) | 语音 | 语音+文本 | ~18GB | 8002 |
| **Fun-CosyVoice3-0.5B** | 语音合成 (TTS) | Token | 语音 | ~4GB | 8002 |
| **Fun-ASR-Nano-2512** | 语音识别 (ASR) | 语音 | 文本 | ~3GB | 8003 |

### 总显存需求

| 配置 | 显存 | 适用 GPU |
|------|------|----------|
| S2S + TTS | ~22GB | RTX 4090 (24GB) |
| S2S + TTS + ASR | ~25GB | A40 (48GB), A100 |

---

## vLLM 兼容性分析

### 模型 vLLM 支持情况

| 模型 | vLLM 支持 | 推荐部署方式 | 说明 |
|------|-----------|--------------|------|
| **Fun-Audio-Chat-8B** | ❌ | 原生推理 | S2S 端到端模型，使用自定义推理框架 |
| **Fun-CosyVoice3-0.5B** | ✅ | vLLM 加速 | 可通过 `load_vllm=True` 启用 |
| **Fun-ASR-Nano-2512** | ❌ | funasr 框架 | 专用 ASR 框架，非 LLM 架构 |
| **Whisper-large-v3** | ✅ | vLLM 原生 | OpenAI ASR，vLLM 内置支持 |

### vLLM v0.11+ ASR 支持

vLLM v0.11+ (vLLM-Omni) 支持以下 ASR 模型：

```yaml
内置支持:
  - Whisper (openai/whisper-large-v3)
  - Voxtral (mistralai/Voxtral-Mini-3B-2507)
  - Gemma3n

API 端点:
  - POST /v1/audio/transcriptions  # 语音转文本
  - POST /v1/audio/translations    # 语音翻译为英文
```

### 两种 ASR 部署方案对比

| 方案 | ASR 模型 | 优势 | 劣势 |
|------|----------|------|------|
| **方案 A: funasr** | Fun-ASR-Nano-2512 | 中文方言支持、31语言、热词 | 非 vLLM 统一架构 |
| **方案 B: vLLM** | Whisper-large-v3 | vLLM 统一部署、OpenAI 兼容 | 中文方言支持弱 |

### 方案 A: 混合部署 (推荐中文场景)

```
┌─────────────────────────────────────────────────────────────┐
│                  混合部署架构                                 │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────┐  ┌─────────────────┐  ┌────────────┐  │
│  │  S2S 服务        │  │  TTS 服务       │  │  ASR 服务   │  │
│  │  (原生推理)      │  │  (vLLM 加速)    │  │  (funasr)  │  │
│  │                 │  │                 │  │            │  │
│  │ Fun-Audio-Chat  │  │ CosyVoice3      │  │ Fun-ASR    │  │
│  │ Port: 8002      │  │ Port: 8004      │  │ Port: 8003 │  │
│  └─────────────────┘  └─────────────────┘  └────────────┘  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 方案 B: 全 vLLM 部署 (统一架构)

```
┌─────────────────────────────────────────────────────────────┐
│                  全 vLLM 部署架构                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────┐  ┌─────────────────┐  ┌────────────┐  │
│  │  S2S 服务        │  │  TTS 服务       │  │  ASR 服务   │  │
│  │  (原生推理)      │  │  (vLLM)         │  │  (vLLM)    │  │
│  │                 │  │                 │  │            │  │
│  │ Fun-Audio-Chat  │  │ CosyVoice3      │  │ Whisper    │  │
│  │ Port: 8002      │  │ Port: 8004      │  │ Port: 8005 │  │
│  └─────────────────┘  └─────────────────┘  └────────────┘  │
│                                                             │
│  TTS + ASR 可合并为单个 vLLM 实例 (多模型服务)               │
└─────────────────────────────────────────────────────────────┘
```

**vLLM 统一部署启动**:

```bash
# 单 vLLM 实例服务 TTS + ASR
vllm serve openai/whisper-large-v3 \
    --port 8005 \
    --task transcription \
    --gpu-memory-utilization 0.3

# 或使用 Python 启动多模型
python -m vllm.entrypoints.openai.api_server \
    --model openai/whisper-large-v3 \
    --port 8005
```

### vLLM 版本要求

```yaml
推荐版本:
  vLLM: >= 0.11.0 (Omni 多模态支持)
  PyTorch: 2.7.0+
  CUDA: 12.x

安装:
  pip install 'vllm[audio]>=0.11.0'

注意事项:
  - vLLM 版本可能与基础环境存在依赖冲突
  - 建议使用独立虚拟环境
  - Whisper 有 30 秒音频限制，需自行分片
```

### CosyVoice vLLM 使用方式

```python
from cosyvoice.cli.cosyvoice import AutoModel

# 启用 vLLM 加速
cosyvoice = AutoModel(
    model_dir='pretrained_models/Fun-CosyVoice3-0.5B-2512',
    load_trt=True,      # TensorRT 加速
    load_vllm=True,     # vLLM 加速
    fp16=False
)

# Zero-shot 推理
for chunk in cosyvoice.inference_zero_shot(
    tts_text="你好，我是语音助手",
    prompt_text="You are a helpful assistant.",
    prompt_wav="./prompt.wav",
    stream=True
):
    audio_chunk = chunk['tts_speech']
```

### Whisper vLLM 使用方式 (ASR)

```bash
# 调用 vLLM Whisper 服务
curl -X POST http://localhost:8005/v1/audio/transcriptions \
    -H "Authorization: Bearer $VLLM_API_KEY" \
    -F "file=@audio.wav" \
    -F "model=openai/whisper-large-v3" \
    -F "language=zh"
```

```python
# Python 客户端
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8005/v1",
    api_key="token"
)

with open("audio.wav", "rb") as f:
    result = client.audio.transcriptions.create(
        model="openai/whisper-large-v3",
        file=f,
        language="zh"
    )
print(result.text)
```

### 内置 TTS vs 独立 TTS 对比

| 特性 | 内置 TTS (S2S) | 独立 TTS 服务 |
|------|----------------|---------------|
| 输入 | Audio Tokens | 文本 |
| 用途 | S2S 流程专用 | 通用 TTS API |
| vLLM | 不适用 | 可用 |
| 独立调用 | ❌ | ✅ |

### Fun-ASR vs Whisper 对比

| 特性 | Fun-ASR-Nano-2512 | Whisper-large-v3 |
|------|-------------------|------------------|
| 框架 | funasr (专用) | vLLM (通用) |
| 中文 | 优秀 (含方言) | 良好 |
| 语言数 | 31 + 7方言 | 99 |
| 热词 | ✅ 支持 | ❌ 不支持 |
| 实时性 | 低延迟 | 中等 |
| 部署 | 独立服务 | vLLM 统一 |

**结论**:
- 中文为主 → 推荐 **方案 A** (Fun-ASR)
- 统一架构 / 多语言 → 推荐 **方案 B** (Whisper + vLLM)

### 全 vLLM 部署脚本

项目提供一键启动脚本：

```bash
# 启动全 vLLM 服务 (S2S + TTS-vLLM + ASR-Whisper)
./scripts/start_vllm_services.sh

# 自定义端口
S2S_PORT=8002 TTS_PORT=8004 ASR_PORT=8005 ./scripts/start_vllm_services.sh

# 停止所有服务
./scripts/stop_services.sh
```

**全 vLLM 服务端点**:

| 服务 | 端点 | 协议 |
|------|------|------|
| S2S | `ws://host:8002/api/chat` | WebSocket |
| TTS | `POST http://host:8004/api/synthesize` | HTTP |
| ASR | `POST http://host:8005/v1/audio/transcriptions` | OpenAI 兼容 |

**ASR 调用示例 (OpenAI 兼容)**:

```bash
curl -X POST http://localhost:8005/v1/audio/transcriptions \
    -F "file=@audio.wav" \
    -F "model=openai/whisper-large-v3" \
    -F "language=zh"
```

```python
from openai import OpenAI

client = OpenAI(base_url="http://localhost:8005/v1", api_key="token")

with open("audio.wav", "rb") as f:
    result = client.audio.transcriptions.create(
        model="openai/whisper-large-v3",
        file=f,
        language="zh"
    )
print(result.text)
```

---

## 三模型详解

### 1. Fun-Audio-Chat-8B (S2S 语音对话)

#### 模型特性

```yaml
名称: Fun-Audio-Chat-8B
类型: 多模态语音对话大模型
参数: ~8B
核心技术:
  - 双分辨率语音表征: 5Hz共享骨干 + 25Hz精细化头部
  - 端到端语音对话 (Speech-to-Speech)
  - 支持语音函数调用
  - 情感共鸣响应
```

#### 获取方式

```bash
# HuggingFace
huggingface-cli download FunAudioLLM/Fun-Audio-Chat-8B \
    --local-dir ./pretrained_models/Fun-Audio-Chat-8B

# ModelScope
modelscope download --model FunAudioLLM/Fun-Audio-Chat-8B \
    --local_dir pretrained_models/Fun-Audio-Chat-8B
```

#### 集成方式

- **进程**: 主服务进程内加载
- **GPU**: 默认 cuda:0
- **内存**: ~18GB VRAM

---

### 2. Fun-CosyVoice3-0.5B-2512 (TTS 语音合成)

#### 模型特性

```yaml
名称: Fun-CosyVoice3-0.5B-2512
类型: 流式语音合成模型
参数: ~0.5B
核心技术:
  - 高质量流式 TTS
  - 针对 S2S 优化的 Token 解码
  - 支持多说话人嵌入
```

#### 获取方式

```bash
# HuggingFace
huggingface-cli download FunAudioLLM/Fun-CosyVoice3-0.5B-2512 \
    --local-dir ./pretrained_models/Fun-CosyVoice3-0.5B-2512

# ModelScope
modelscope download --model FunAudioLLM/Fun-CosyVoice3-0.5B-2512 \
    --local_dir pretrained_models/Fun-CosyVoice3-0.5B-2512
```

#### 集成方式

- **进程**: 独立子进程 (`tts_worker_process`)
- **GPU**: 可配置 (--tts-gpu)，默认 cuda:1
- **依赖**: `third_party/CosyVoice` 子模块
- **封装**: `utils/cosyvoice_detokenizer.py`

---

### 3. Fun-ASR-Nano-2512 (ASR 语音识别)

#### 模型特性

```yaml
名称: Fun-ASR-Nano-2512
类型: 端到端语音识别模型
参数: ~0.8B
核心技术:
  - 千万小时真实语音训练
  - 支持 31 种语言 + 7 大方言
  - 低延迟实时转录
  - 热词支持
```

#### 获取方式

```bash
# HuggingFace
huggingface-cli download FunAudioLLM/Fun-ASR-Nano-2512 \
    --local-dir ./pretrained_models/Fun-ASR-Nano-2512

# ModelScope
modelscope download --model FunAudioLLM/Fun-ASR-Nano-2512 \
    --local_dir pretrained_models/Fun-ASR-Nano-2512
```

#### 集成方式

- **进程**: 独立服务进程 (`asr_server.py`)
- **GPU**: 可配置 (--device)
- **依赖**: `funasr` 库
- **协议**: HTTP REST API

---

## 部署模式

### 模式 A: 单 GPU 基础部署 (24GB)

适用于 RTX 4090 等 24GB 显存 GPU。

```
┌────────────────────────────────────────┐
│              单 GPU (cuda:0)            │
│  ┌──────────────────────────────────┐  │
│  │      S2S + TTS 主服务              │  │
│  │      (~22GB VRAM)                 │  │
│  └──────────────────────────────────┘  │
│                                        │
│  ❌ ASR 需独立部署或省略                │
└────────────────────────────────────────┘
```

**启动命令**:
```bash
python3 -m web_demo.server.server \
    --model-path pretrained_models/Fun-Audio-Chat-8B \
    --port 8002 \
    --tts-gpu 0 \
    --host 0.0.0.0
```

---

### 模式 B: 双 GPU 完整部署 (推荐)

适用于有多 GPU 的服务器。

```
┌────────────────────────────────────────┐
│           GPU 0 (cuda:0)               │
│  ┌──────────────────────────────────┐  │
│  │      S2S 模型 (~18GB)             │  │
│  └──────────────────────────────────┘  │
└────────────────────────────────────────┘

┌────────────────────────────────────────┐
│           GPU 1 (cuda:1)               │
│  ┌──────────────────────────────────┐  │
│  │      TTS (~4GB) + ASR (~3GB)      │  │
│  └──────────────────────────────────┘  │
└────────────────────────────────────────┘
```

**启动命令**:
```bash
# 终端 1: S2S + TTS 服务
python3 -m web_demo.server.server \
    --model-path pretrained_models/Fun-Audio-Chat-8B \
    --port 8002 \
    --tts-gpu 1 \
    --host 0.0.0.0

# 终端 2: ASR 服务
python3 -m web_demo.server.asr_server \
    --model-path pretrained_models/Fun-ASR-Nano-2512 \
    --port 8003 \
    --device cuda:1 \
    --host 0.0.0.0
```

---

### 模式 C: 大显存单 GPU 完整部署 (A40/A100)

适用于 A40 (48GB) 或 A100 (80GB)。

```
┌────────────────────────────────────────┐
│         单 GPU (cuda:0) 48GB+          │
│  ┌──────────────────────────────────┐  │
│  │  S2S (~18GB) + TTS (~4GB)         │  │
│  │  主服务: Port 8002                 │  │
│  └──────────────────────────────────┘  │
│  ┌──────────────────────────────────┐  │
│  │  ASR (~3GB)                       │  │
│  │  独立服务: Port 8003               │  │
│  └──────────────────────────────────┘  │
│                                        │
│  总计: ~25GB / 48GB                    │
└────────────────────────────────────────┘
```

---

### 模式 D: 三服务独立部署 (含独立 TTS API)

**适用场景**: 需要同时支持 S2S、独立 TTS、独立 ASR 三种调用模式。

```
┌─────────────────────────────────────────────────────────────────────┐
│                    三服务独立架构 (A40/A100)                         │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │  S2S 对话服务        │  │  TTS 合成服务    │  │  ASR 识别服务    │ │
│  │  Port: 8002         │  │  Port: 8004     │  │  Port: 8003     │ │
│  │  协议: WebSocket    │  │  协议: HTTP     │  │  协议: HTTP     │ │
│  │                     │  │                 │  │                 │ │
│  │  Fun-Audio-Chat-8B  │  │  CosyVoice3     │  │  Fun-ASR-Nano   │ │
│  │  + 内置 TTS         │  │  (vLLM 加速)    │  │  (funasr)       │ │
│  │  (~22GB)            │  │  (~4GB)         │  │  (~3GB)         │ │
│  └─────────────────────┘  └─────────────────┘  └─────────────────┘ │
│                                                                     │
│  总显存: ~29GB (需 A40 48GB 或 A100 80GB)                           │
└─────────────────────────────────────────────────────────────────────┘
```

**显存分配**:

| 服务 | GPU | 显存 | 端口 |
|------|-----|------|------|
| S2S + 内置TTS | cuda:0 | ~22GB | 8002 |
| 独立 TTS (vLLM) | cuda:0 | ~4GB | 8004 |
| ASR | cuda:0 | ~3GB | 8003 |

**启动命令**:

```bash
# 1. S2S + 内置 TTS 服务
nohup python3 -m web_demo.server.server \
    --model-path pretrained_models/Fun-Audio-Chat-8B \
    --port 8002 \
    --tts-gpu 0 \
    --host 0.0.0.0 \
    > server.log 2>&1 &

# 2. 独立 TTS 服务 (需创建 tts_server.py)
nohup python3 -m web_demo.server.tts_server \
    --model-path pretrained_models/Fun-CosyVoice3-0.5B-2512 \
    --port 8004 \
    --device cuda:0 \
    --use-vllm \
    --host 0.0.0.0 \
    > tts_server.log 2>&1 &

# 3. ASR 服务
nohup python3 -m web_demo.server.asr_server \
    --model-path pretrained_models/Fun-ASR-Nano-2512 \
    --port 8003 \
    --device cuda:0 \
    --host 0.0.0.0 \
    > asr_server.log 2>&1 &
```

**注意**: 独立 TTS 服务 (tts_server.py) 需要单独开发，见下文"独立 TTS 服务实现"。

**启动命令**:
```bash
# 后台启动 S2S + TTS
nohup python3 -m web_demo.server.server \
    --model-path pretrained_models/Fun-Audio-Chat-8B \
    --port 8002 \
    --tts-gpu 0 \
    --host 0.0.0.0 \
    > server.log 2>&1 &

# 后台启动 ASR
nohup python3 -m web_demo.server.asr_server \
    --model-path pretrained_models/Fun-ASR-Nano-2512 \
    --port 8003 \
    --device cuda:0 \
    --host 0.0.0.0 \
    > asr_server.log 2>&1 &
```

---

## 接口规范

### 1. S2S 语音对话接口 (WebSocket)

**端点**: `ws://<host>:8002/api/chat`

#### 协议格式

| 类型 | 方向 | 格式 | 说明 |
|------|------|------|------|
| handshake | S→C | Binary | 握手包 |
| audio | C↔S | `\x01` + opus_bytes | Opus 编码音频 |
| text | S→C | `\x02` + utf8_bytes | 文本消息 |
| control | C→S | JSON | 控制信号 |
| metadata | C→S | JSON | 会话元数据 |

#### 控制信号

```javascript
// 开始录音
{"type": "control", "action": "start"}

// 暂停录音
{"type": "control", "action": "pause"}

// 结束轮次
{"type": "control", "action": "endTurn"}

// 设置系统提示
{"type": "metadata", "data": {"system_prompt": "你是一个友好的助手"}}
```

#### 交互时序

```
Client                          Server
  |                               |
  |-------- WebSocket Connect --->|
  |<------- Handshake ------------|
  |                               |
  |-------- control: start ------>|
  |-------- audio (opus) -------->|  (多帧)
  |-------- control: pause ------>|
  |                               |
  |<------- text (processing) ----|
  |<------- audio (opus) ---------|  (流式返回)
  |<------- text (final) ---------|
  |                               |
  |-------- control: start ------>|  (下一轮)
```

---

### 2. ASR 语音识别接口 (HTTP)

**端点**: `POST http://<host>:8003/api/transcribe`

#### 请求参数 (multipart/form-data)

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| audio | file | 是 | 音频文件 (wav/mp3/flac) |
| language | string | 否 | 识别语言，默认 "中文" |
| hotwords | string | 否 | 热词，逗号分隔 |

#### 响应格式

```json
{
    "text": "识别出的文本内容",
    "language": "中文",
    "success": true
}
```

#### 示例请求

```bash
curl -X POST http://localhost:8003/api/transcribe \
    -F "audio=@test.wav" \
    -F "language=中文" \
    -F "hotwords=Fun-Audio-Chat,语音助手"
```

---

### 3. TTS 语音合成接口 (HTTP) - 独立服务

**端点**: `POST http://<host>:8004/api/synthesize`

#### 请求参数 (JSON)

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| text | string | 是 | 要合成的文本 |
| speaker_id | string | 否 | 说话人 ID，默认 "中文女" |
| prompt_wav | string | 否 | 参考音频路径 (zero-shot) |
| prompt_text | string | 否 | 参考音频对应文本 |
| stream | boolean | 否 | 是否流式返回，默认 false |

#### 响应格式

**非流式模式**:
```json
{
    "audio": "<base64_encoded_wav>",
    "sample_rate": 24000,
    "duration": 3.5,
    "success": true
}
```

**流式模式**: 返回 `audio/wav` 二进制流

#### 示例请求

```bash
# 基础合成
curl -X POST http://localhost:8004/api/synthesize \
    -H "Content-Type: application/json" \
    -d '{"text": "你好，我是语音助手。", "speaker_id": "中文女"}' \
    -o output.wav

# Zero-shot 克隆
curl -X POST http://localhost:8004/api/synthesize \
    -H "Content-Type: application/json" \
    -d '{
        "text": "你好，我是语音助手。",
        "prompt_wav": "/path/to/reference.wav",
        "prompt_text": "这是参考音频的文本"
    }' \
    -o output.wav
```

---

### 4. 健康检查接口 (HTTP)

**ASR 健康检查**: `GET http://<host>:8003/health`

```json
{
    "status": "healthy",
    "model": "Fun-ASR-Nano-2512",
    "device": "cuda:0"
}
```

**TTS 健康检查**: `GET http://<host>:8004/health`

```json
{
    "status": "healthy",
    "model": "Fun-CosyVoice3-0.5B-2512",
    "device": "cuda:0",
    "vllm_enabled": true
}
```

---

## 集成部署流程

### 一键部署脚本

#### 环境准备

```bash
#!/bin/bash
# scripts/full_setup.sh

set -e
echo "=== Fun-Audio-Chat 完整部署 ==="

# 1. 系统依赖
apt update && apt install -y ffmpeg

# 2. PyTorch + CUDA
pip install torch==2.8.0 torchaudio==2.8.0 torchvision==0.23.0 \
    --index-url https://download.pytorch.org/whl/cu128

# 3. Web 依赖
pip install sphn aiohttp

# 4. 项目依赖
pip install -r requirements.txt
pip install 'ruamel.yaml<0.18' --force-reinstall

# 5. ASR 依赖
pip install funasr

echo "=== 依赖安装完成 ==="
```

#### 模型下载

```bash
#!/bin/bash
# scripts/download_models.sh

set -e
pip install huggingface-hub

# S2S 模型
if [ ! -d "pretrained_models/Fun-Audio-Chat-8B" ]; then
    echo "下载 Fun-Audio-Chat-8B..."
    huggingface-cli download FunAudioLLM/Fun-Audio-Chat-8B \
        --local-dir ./pretrained_models/Fun-Audio-Chat-8B
fi

# TTS 模型
if [ ! -d "pretrained_models/Fun-CosyVoice3-0.5B-2512" ]; then
    echo "下载 Fun-CosyVoice3-0.5B-2512..."
    huggingface-cli download FunAudioLLM/Fun-CosyVoice3-0.5B-2512 \
        --local-dir ./pretrained_models/Fun-CosyVoice3-0.5B-2512
fi

# ASR 模型
if [ ! -d "pretrained_models/Fun-ASR-Nano-2512" ]; then
    echo "下载 Fun-ASR-Nano-2512..."
    huggingface-cli download FunAudioLLM/Fun-ASR-Nano-2512 \
        --local-dir ./pretrained_models/Fun-ASR-Nano-2512
fi

echo "=== 模型下载完成 ==="
```

#### 服务启动

```bash
#!/bin/bash
# scripts/start_services.sh

set -e
cd /workspace/Fun-Audio-Chat
export PYTHONPATH=$(pwd)

# 参数解析
TTS_GPU=${1:-0}
ASR_DEVICE=${2:-cuda:0}

echo "=== 启动服务 ==="
echo "TTS GPU: $TTS_GPU"
echo "ASR Device: $ASR_DEVICE"

# 启动 S2S + TTS 服务
echo "启动 S2S + TTS 服务..."
nohup python3 -m web_demo.server.server \
    --model-path pretrained_models/Fun-Audio-Chat-8B \
    --port 8002 \
    --tts-gpu $TTS_GPU \
    --host 0.0.0.0 \
    > server.log 2>&1 &

echo "S2S 服务 PID: $!"

# 等待 S2S 模型加载
sleep 30

# 启动 ASR 服务
echo "启动 ASR 服务..."
nohup python3 -m web_demo.server.asr_server \
    --model-path pretrained_models/Fun-ASR-Nano-2512 \
    --port 8003 \
    --device $ASR_DEVICE \
    --host 0.0.0.0 \
    > asr_server.log 2>&1 &

echo "ASR 服务 PID: $!"

echo "=== 服务启动完成 ==="
echo "S2S: ws://0.0.0.0:8002/api/chat"
echo "ASR: http://0.0.0.0:8003/api/transcribe"
```

---

### 验证部署

```bash
#!/bin/bash
# scripts/verify_deployment.sh

echo "=== 验证部署 ==="

# 检查端口
echo "检查端口监听..."
ss -tlnp | grep -E '8002|8003'

# 检查进程
echo "检查服务进程..."
ps aux | grep -E 'web_demo.server' | grep -v grep

# 检查 GPU 使用
echo "检查 GPU 使用..."
nvidia-smi --query-gpu=name,memory.used,memory.total --format=csv

# ASR 健康检查
echo "ASR 健康检查..."
curl -s http://localhost:8003/health | python3 -m json.tool

# 检查日志
echo "最近日志..."
tail -5 server.log
tail -5 asr_server.log

echo "=== 验证完成 ==="
```

---

## 运维监控

### GPU 监控

```bash
# 实时监控
watch -n 1 nvidia-smi

# 简洁输出
nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv
```

### 日志监控

```bash
# S2S 服务日志
tail -f server.log

# ASR 服务日志
tail -f asr_server.log

# 合并监控
tail -f server.log asr_server.log
```

### 服务管理

```bash
# 停止所有服务
pkill -f 'web_demo.server'

# 重启服务
pkill -f 'web_demo.server'
sleep 5
./scripts/start_services.sh
```

### 健康检查

```bash
# ASR 服务
curl http://localhost:8003/health

# S2S 服务 (通过 WebSocket 连接测试)
python3 scripts/test_deployment.py --host localhost --port 8002
```

---

## 附录: 文件结构

```
Fun-Audio-Chat/
├── web_demo/
│   └── server/
│       ├── server.py          # S2S + 内置TTS 主服务 (Port 8002)
│       ├── tts_server.py      # 独立 TTS 服务 (Port 8004) ★ 新增
│       ├── asr_server.py      # ASR 独立服务 (Port 8003)
│       ├── protocal.py        # WebSocket 协议
│       └── funaudiochat_infer.py  # 推理封装
├── utils/
│   ├── cosyvoice_detokenizer.py   # TTS 封装 (供 S2S 内部使用)
│   ├── cosyvoice_tokenizer.py     # Token 处理
│   └── constant.py            # 常量配置
├── third_party/
│   └── CosyVoice/             # Git 子模块 (含 vLLM 支持)
├── pretrained_models/
│   ├── Fun-Audio-Chat-8B/     # S2S 模型
│   ├── Fun-CosyVoice3-0.5B-2512/  # TTS 模型
│   └── Fun-ASR-Nano-2512/     # ASR 模型
├── scripts/
│   ├── runpod_manager.py      # RunPod 管理
│   ├── auto_deploy.py         # 自动部署
│   ├── test_deployment.py     # 部署测试
│   ├── start_vllm_services.sh # 全 vLLM 部署启动 ★ 新增
│   └── stop_services.sh       # 停止所有服务 ★ 新增
└── deploy/
    └── 集成部署模式.md        # 本文档
```

---

## 三服务接口汇总 (最终方案)

| 服务 | 推理方式 | 端口 | 端点 | 功能 |
|------|----------|------|------|------|
| **S2S** | 原生推理 | 8002 | `ws://.../api/chat` | 语音→语音+文本 |
| **ASR** | funasr | 8003 | `POST /api/transcribe` | 语音→文本 |
| **TTS** | vLLM可选 | 8004 | `POST /api/synthesize` | 文本→语音 |

**启动命令**:
```bash
# 基础服务 (S2S + ASR)
./scripts/start_services.sh

# 完整服务 (S2S + ASR + 独立TTS)
./scripts/start_services.sh --with-tts --use-vllm
```

---

## 版本历史

| 版本 | 日期 | 变更 |
|------|------|------|
| v1.3 | 2026-01-08 | **最终方案**: S2S原生 + TTS(vLLM可选) + ASR(funasr) |
| v1.2 | 2026-01-08 | 添加全 vLLM 部署方案 (ASR 使用 Whisper)，启动脚本 |
| v1.1 | 2026-01-08 | 添加独立 TTS 服务，vLLM 兼容性分析，三服务架构 |
| v1.0 | 2026-01-08 | 初始版本，三模型集成部署方案 |

---

## 参考链接

- [Fun-Audio-Chat GitHub](https://github.com/FunAudioLLM/Fun-Audio-Chat)
- [CosyVoice GitHub](https://github.com/FunAudioLLM/CosyVoice)
- [Fun-ASR GitHub](https://github.com/FunAudioLLM/Fun-ASR)
- [vLLM TTS Support Issue](https://github.com/vllm-project/vllm/issues/11964)
