# Fun-Audio-Chat 实时语音接口接入方式

> 快速接入指南 v1.0 | 2026-01-07

---

## 一、服务信息

### 当前部署

| 项目 | 值 |
|------|-----|
| 服务地址 | `194.68.245.6` |
| WebSocket端口 | `22035` (映射自内部8002) |
| SSH端口 | `22032` |
| GPU | NVIDIA A40 (48GB) |
| 模型 | Fun-Audio-Chat-8B + CosyVoice3-0.5B |

### 接口端点

```
WebSocket: ws://194.68.245.6:22035/api/chat
```

---

## 二、快速接入

### 2.1 WebSocket 连接

```javascript
// 建立连接
const ws = new WebSocket('ws://194.68.245.6:22035/api/chat');
ws.binaryType = 'arraybuffer';

ws.onopen = () => {
  console.log('Connected to Fun-Audio-Chat');
};

ws.onmessage = (event) => {
  handleMessage(event.data);
};
```

### 2.2 消息协议

#### 二进制消息格式

```
┌─────────┬──────────────────────────┐
│ 1 byte  │      Payload             │
├─────────┼──────────────────────────┤
│  Type   │      Data                │
└─────────┴──────────────────────────┘

Type:
  0x01 = 音频数据 (Opus编码)
  0x02 = 文本数据 (UTF-8)
```

#### JSON 控制消息

```javascript
// 客户端发送
{ "type": "start" }      // 开始说话
{ "type": "pause" }      // 停止说话
{ "type": "endTurn" }    // 结束本轮

// 服务端返回
{ "type": "listening" }  // 等待用户输入
{ "type": "processing" } // 正在处理
{ "type": "speaking" }   // AI正在说话
{ "type": "endTurn" }    // AI说完了
```

---

## 三、音频参数

| 参数 | 值 |
|------|-----|
| 采样率 | 24000 Hz |
| 声道数 | 1 (单声道) |
| 编码格式 | Opus |
| 帧大小 | 960 samples (40ms) |
| 比特率 | 24kbps |

---

## 四、完整接入示例

### 4.1 发送音频

```javascript
// 发送 Opus 编码的音频
function sendAudio(opusData) {
  const message = new Uint8Array(1 + opusData.length);
  message[0] = 0x01;  // 音频类型
  message.set(opusData, 1);
  ws.send(message);
}

// 开始录音流程
function startRecording() {
  ws.send(JSON.stringify({ type: 'start' }));
  // 开始采集麦克风并编码发送...
}

// 停止录音
function stopRecording() {
  ws.send(JSON.stringify({ type: 'pause' }));
}
```

### 4.2 接收消息

```javascript
function handleMessage(data) {
  if (typeof data === 'string') {
    // JSON 控制消息
    const control = JSON.parse(data);
    console.log('Control:', control.type);

    if (control.type === 'listening') {
      // 可以开始说话了
    } else if (control.type === 'speaking') {
      // AI开始回复
    }
  } else {
    // 二进制消息
    const bytes = new Uint8Array(data);
    const type = bytes[0];
    const payload = bytes.slice(1);

    if (type === 0x01) {
      // Opus 音频数据 → 解码播放
      playOpusAudio(payload);
    } else if (type === 0x02) {
      // UTF-8 文本
      const text = new TextDecoder().decode(payload);
      console.log('AI:', text);
    }
  }
}
```

### 4.3 完整交互流程

```
1. 建立 WebSocket 连接
2. 收到 { type: 'listening' } → 可以开始说话
3. 发送 { type: 'start' }
4. 持续发送 0x01 + Opus音频数据
5. 说完后发送 { type: 'pause' }
6. 收到 { type: 'processing' } → AI正在处理
7. 收到 { type: 'speaking' } → AI开始回复
8. 持续收到 0x01 音频 + 0x02 文本
9. 收到 { type: 'endTurn' } → AI说完
10. 收到 { type: 'listening' } → 等待下一轮
```

---

## 五、前端 SDK 使用

### 5.1 安装依赖

```bash
npm install opus-recorder  # Opus 编解码
```

### 5.2 React Hook 示例

```typescript
import { useState, useRef, useCallback } from 'react';

function useVoiceChat(wsUrl: string) {
  const [state, setState] = useState<'idle'|'listening'|'speaking'>('idle');
  const wsRef = useRef<WebSocket | null>(null);

  const connect = useCallback(() => {
    wsRef.current = new WebSocket(wsUrl);
    wsRef.current.binaryType = 'arraybuffer';

    wsRef.current.onmessage = (e) => {
      if (typeof e.data === 'string') {
        const msg = JSON.parse(e.data);
        if (msg.type === 'listening') setState('listening');
        if (msg.type === 'speaking') setState('speaking');
      } else {
        // 处理音频/文本
      }
    };
  }, [wsUrl]);

  const startTalking = useCallback(() => {
    wsRef.current?.send(JSON.stringify({ type: 'start' }));
  }, []);

  const stopTalking = useCallback(() => {
    wsRef.current?.send(JSON.stringify({ type: 'pause' }));
  }, []);

  return { state, connect, startTalking, stopTalking };
}
```

---

## 六、Python 测试客户端

```python
import asyncio
import websockets
import json

async def test_connection():
    uri = "ws://194.68.245.6:22035/api/chat"

    async with websockets.connect(uri) as ws:
        print("Connected!")

        # 发送开始信号
        await ws.send(json.dumps({"type": "start"}))

        # 接收消息
        while True:
            try:
                msg = await asyncio.wait_for(ws.recv(), timeout=10)

                if isinstance(msg, bytes):
                    msg_type = msg[0]
                    if msg_type == 0x01:
                        print(f"Audio: {len(msg)-1} bytes")
                    elif msg_type == 0x02:
                        text = msg[1:].decode('utf-8')
                        print(f"Text: {text}")
                else:
                    print(f"Control: {msg}")

            except asyncio.TimeoutError:
                break

asyncio.run(test_connection())
```

---

## 七、错误处理

| 错误码 | 说明 | 处理方式 |
|--------|------|----------|
| `E001` | 会话过期 | 重新建立连接 |
| `E002` | 认证失败 | 检查Token |
| `E004` | 模型不可用 | 稍后重试 |
| `E005` | 音频解码失败 | 检查Opus编码 |

```javascript
ws.onerror = (error) => {
  console.error('WebSocket error:', error);
};

ws.onclose = (event) => {
  if (event.code !== 1000) {
    // 非正常关闭，尝试重连
    setTimeout(connect, 3000);
  }
};
```

---

## 八、性能指标

| 指标 | 目标值 |
|------|--------|
| 首包延迟 | < 500ms |
| 端到端延迟 | < 2s |
| 重连时间 | < 3s |

---

## 九、管理命令

```bash
# 查看服务状态
python3 scripts/auto_deploy.py --status

# SSH 连接到服务器
ssh root@194.68.245.6 -p 22032 -i ~/.ssh/id_ed25519

# 查看服务日志
ssh ... "tail -f /workspace/Fun-Audio-Chat/server.log"

# 检查GPU状态
ssh ... "nvidia-smi"

# 停止Pod (停止计费)
python3 scripts/runpod_manager.py --action stop --pod-id 0mg01rh7zo347n

# 启动Pod
python3 scripts/runpod_manager.py --action start --pod-id 0mg01rh7zo347n
```

---

## 十、下一步

1. **集成到前端**: 使用上述SDK接入App/Web
2. **接入DeepAgent**: 通过Voice-Agent Bridge连接LangGraph
3. **接入Celery触发**: 实现主动语音呼叫

详细架构参考:
- `docs/api/voice-api-specification.md`
- `xdan_finance_platform/doc/智能提醒/Vibe 方案/Fun-Audio-Chat-集成架构.md`

---

*Fun-Audio-Chat 实时语音接口接入方式 v1.0*
