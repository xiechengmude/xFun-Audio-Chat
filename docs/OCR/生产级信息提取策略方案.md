# 生产级信息提取策略方案

> 版本: v1.0 | 2026-02-06 | 基于 GLM-OCR A40 实测经验

## 1. 问题背景

单次 OCR 识别存在不可避免的错误，尤其在：
- 手写体形近字（邓→双）
- 手写数字+字母混淆（12D→522）
- 低分辨率/模糊区域
- 印章覆盖文字

直接依赖单次识别结果做结构化提取，**不满足生产级精度要求**。

### 实测案例（房屋租赁备案 22 页 PDF）

| 字段 | OCR 结果 | 正确值 | 出错原因 |
|------|---------|--------|---------|
| 承租人（Page 1） | 双锦兰 | 邓锦兰 | 手写体形近字 |
| 地址（Page 1） | 1栋522 | 1栋5层12D | 手写数字+字母 |
| 承租人（Page 4） | 邓锦兰 | 邓锦兰 | 印刷体，正确 |
| 身份证号（全页） | 440921198804124527 | 440921198804124527 | 数字，全部正确 |

**关键观察**: 同一信息在文档中多处出现时，大部分识别正确，少数出错 → 可通过交叉校验纠错。

## 2. 六层防御架构

```
PDF/图片输入
  │
  ├── Layer 1: 全页 OCR（GLM-OCR 并发）──► 纯文本
  │
  ├── Layer 2: 布局检测（PP-DocLayout）──► 区域分割
  │
  ├── Layer 3: 多次推理投票（Self-Consistency）──► 去噪
  │
  ├── Layer 4: LLM 结构化抽取（Claude/GPT-4o）──► JSON 填充
  │
  ├── Layer 5: 规则校验（正则 + 业务逻辑）──► 格式纠错
  │
  └── Layer 6: 置信度评估 + 人工审核兜底 ──► 最终输出
```

## 3. 各层详细设计

### Layer 1: 全页 OCR

直接使用现有 GLM-OCR API，并发处理所有页面：

```python
# 已有能力，无需改动
response = await client.post("/api/ocr/document", files={"file": pdf}, data={"pages": "all"})
pages = response.json()["pages"]  # [{page_number, text, regions}, ...]
```

**性能**: 22页 → 19.74s（1.11 pgs/s），可接受。

### Layer 2: 布局检测区域分割

PP-DocLayout-V3 将页面分割为语义区域，为后续精准提取提供定位：

```python
regions = [
    {"label": "text", "bbox": [100, 50, 500, 200], "score": 0.95},
    {"label": "table", "bbox": [100, 300, 600, 500], "score": 0.92},
    {"label": "seal", "bbox": [400, 600, 550, 750], "score": 0.88},
]
```

**作用**: 区分正文/表格/印章/手写区域，对不同区域采用不同识别策略。

### Layer 3: 多次推理投票（Self-Consistency）

对关键区域做 3 次 OCR，字段级投票取多数一致结果：

```python
async def ocr_with_voting(image: bytes, task: str = "text", n_votes: int = 3) -> dict:
    """多次推理 + 投票去噪"""
    temperatures = [0.1, 0.3, 0.5][:n_votes]

    tasks = [
        call_vllm(image, task=task, temperature=t)
        for t in temperatures
    ]
    results = await asyncio.gather(*tasks)

    # 字段级投票（对结构化输出）
    if task == "extract":
        return field_level_vote(results)

    # 文本级投票（对纯文本输出）
    return text_majority_vote(results)


def field_level_vote(results: list[dict]) -> dict:
    """对每个字段独立投票"""
    all_keys = set()
    for r in results:
        all_keys.update(r.keys())

    voted = {}
    for key in all_keys:
        values = [r.get(key) for r in results if r.get(key)]
        # 取出现次数最多的值
        voted[key] = Counter(values).most_common(1)[0][0] if values else None
    return voted
```

**成本**: 单图 1.16s × 3 次并发 ≈ 1.5s（vLLM 批处理能力），可接受。

### Layer 4: 跨页交叉校验 + LLM 结构化抽取

**两阶段 Pipeline**：OCR 和结构化提取分离，各司其职。

```python
async def extract_with_cross_validation(pages: list[dict], schema: dict) -> dict:
    """
    Stage 1: 收集所有页面的 OCR 文本
    Stage 2: 用 LLM 做跨页结构化抽取 + 自动纠错
    """
    # 拼接全文档文本
    full_text = "\n\n".join([
        f"=== 第{p['page_number']}页 ===\n{p['text']}"
        for p in pages
    ])

    # LLM 结构化抽取（Claude / GPT-4o）
    prompt = f"""从以下文档 OCR 文本中提取信息，按 JSON schema 填充。

注意：
1. 同一字段可能在多页出现，取出现最多次的值（OCR 可能有个别错误）
2. 如果某字段多处出现但值不一致，选择出现频率最高且格式合理的
3. 身份证号必须是18位，手机号必须是11位
4. 对不确定的字段标注 confidence: "low"

JSON Schema:
{json.dumps(schema, ensure_ascii=False, indent=2)}

文档文本:
{full_text}
"""
    result = await call_llm(prompt)
    return result
```

**优势**:
- GLM-OCR 专注高速识别，LLM 专注理解和纠错
- LLM 能利用上下文推断正确值（"双锦兰" 在其他 8 处都是 "邓锦兰" → 纠正）
- Schema 约束确保输出格式一致

### Layer 5: 规则校验

对关键字段做后处理格式校验：

```python
VALIDATORS = {
    "id_number": {
        "pattern": r"^\d{17}[\dX]$",
        "checksum": verify_id_checksum,       # 身份证校验位验证
        "description": "18位身份证号",
    },
    "phone": {
        "pattern": r"^1[3-9]\d{9}$",
        "description": "11位手机号",
    },
    "date": {
        "parser": parse_chinese_date,          # "2025年3月3日" → "2025-03-03"
        "range": ("2020-01-01", "2030-12-31"), # 合理范围
    },
    "amount": {
        "cross_check": validate_amount_cn_vs_digit,  # 大小写金额一致性
        # "贰仟元" vs "2000元" → 一致 ✓
    },
    "area": {
        "pattern": r"^\d+\.?\d*$",
        "unit": "平方米",
    },
}

def validate_field(field_name: str, value: str) -> dict:
    """校验单个字段，返回校验结果"""
    validator = VALIDATORS.get(field_name)
    if not validator:
        return {"value": value, "valid": True}

    if "pattern" in validator:
        if not re.match(validator["pattern"], value):
            return {"value": value, "valid": False, "reason": f"格式不匹配: {validator['description']}"}

    if "checksum" in validator:
        if not validator["checksum"](value):
            return {"value": value, "valid": False, "reason": "校验位错误"}

    return {"value": value, "valid": True}
```

### Layer 6: 置信度评估 + 人工审核

利用 vLLM 返回的 token logprobs 计算字段级置信度：

```python
async def ocr_with_confidence(image: bytes, task: str) -> dict:
    """带置信度的 OCR"""
    response = await call_vllm(image, task=task, logprobs=True, top_logprobs=5)

    text = response["text"]
    token_logprobs = response["logprobs"]

    # 计算平均置信度
    avg_confidence = math.exp(sum(token_logprobs) / len(token_logprobs))

    return {
        "text": text,
        "confidence": avg_confidence,
        "needs_review": avg_confidence < 0.85,  # 低于阈值标记人工审核
    }
```

**最终输出格式**:

```json
{
    "document_type": "房屋租赁备案",
    "extracted": {
        "出租人": {
            "value": "陆逸 石少玲",
            "confidence": 0.97,
            "sources": [1, 4, 10],
            "valid": true
        },
        "承租人": {
            "value": "邓锦兰",
            "confidence": 0.94,
            "sources": [1, 4, 10, 22],
            "valid": true,
            "note": "Page 1 识别为'双锦兰'，已通过跨页投票纠正"
        },
        "身份证号_承租人": {
            "value": "440921198804124527",
            "confidence": 0.99,
            "valid": true,
            "checksum": "pass"
        },
        "地址": {
            "value": "深圳市南山区北环大道深云村8栋28B",
            "confidence": 0.71,
            "needs_review": true,
            "note": "Page 1 识别为'522'，Page 4/5 识别为'28B'，已纠正但置信度偏低"
        }
    },
    "review_required": ["地址"],
    "processing_time": 3.2
}
```

## 4. 性能预估

| 阶段 | 耗时（22页 PDF） | 说明 |
|------|-----------------|------|
| 全页 OCR | ~20s | 现有能力 |
| 布局检测 | +3s | PP-DocLayout CPU |
| 多次投票 | +5s | 关键区域 ×3 并发 |
| LLM 抽取 | +2s | Claude API 调用 |
| 规则校验 | <0.1s | 纯 CPU |
| **总计** | **~30s** | 22 页完整提取 |

单页简单提取（如身份证）: **~3s**

## 5. 适用场景

| 场景 | 推荐层级 | 预期精度 |
|------|---------|---------|
| 身份证/营业执照 | Layer 1+4+5 | 99%+ |
| 合同关键条款 | Layer 1+3+4+5 | 97%+ |
| 完整合同全字段 | 全部 6 层 | 95%+ |
| 手写表单 | 全部 6 层 + 人工审核 | 90%+ |

## 6. 实现优先级

| 优先级 | 功能 | 工作量 | 价值 |
|--------|------|--------|------|
| P0 | 跨页交叉校验 | 低 | 高 — 零成本纠错 |
| P0 | 规则校验（身份证/电话/日期） | 低 | 高 — 格式级兜底 |
| P1 | LLM 结构化抽取 Pipeline | 中 | 高 — 理解力质变 |
| P1 | 置信度评估 | 中 | 中 — 标记审核字段 |
| P2 | 多次推理投票 | 低 | 中 — 字段级去噪 |
| P2 | 人工审核队列 | 高 | 中 — 兜底保障 |

## 7. 待实现接口（预设计）

```
POST /api/ocr/extract/document
  Body: multipart/form-data
  - file: PDF/图片
  - schema: JSON schema（提取目标字段）
  - pages: str = "all"
  - strategy: str = "standard"  (standard / high_accuracy / fast)
    - fast: Layer 1+4 仅，~5s
    - standard: Layer 1+3+4+5，~15s
    - high_accuracy: 全部 6 层，~30s
  - review_threshold: float = 0.85（低于此值标记人工审核）

  Response:
  {
      "extracted": { ... },       // 结构化提取结果
      "review_required": [...],   // 需人工审核的字段
      "metadata": {
          "strategy": "standard",
          "pages_parsed": 22,
          "processing_time": 15.3,
          "cross_validated_fields": 8,
          "corrections_made": 2
      }
  }
```
